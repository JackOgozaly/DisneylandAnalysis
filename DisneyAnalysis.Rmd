---
title: "Disneyland Analysis"
author: "Jack Ogozaly"
date: "5/5/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Disneyland Analysis

This pdf gives a high level overview of an analysis of Disneyland reviews. This analysis primarily focuses on using natural language processing to extract insights from ~42,000 text reviews of various disneyland reviews. 


The questions this analysis seeks to answer is: 

1) How are the different Disneyland branches performing? 

2) What rides are reviewers talking the most about? 

3) What are reviewers saying about Disneyland? 

4) What are some positive things guests say about the parks? 

5) What are some negative things guests say about the parks?


```{r, message=FALSE, include=FALSE, cache=TRUE, warning=FALSE}
library(tidyverse) #used for everything
library(tm)        #Used for NLP 
library(tidytext)  #used for NLP 
library(openxlsx)  #Used to read in data
library(ggthemes)  #Used to make graphs look good
library(knitr)
#Read in our data
setwd("C:/Users/jogoz/OneDrive/Desktop/ISOM Spring 2021/Data Visualization/New Final Project")
disney_data <- read_csv("DisneyLandReviews.csv")

#Some names are not correctly formatted, so first we change that
disney_data$Reviewer_Location <-  iconv(disney_data$Reviewer_Location, 
                                        from = 'UTF-8', to = 'ASCII//TRANSLIT')
#Remove any NAs in our data
disney_data <- na.omit(disney_data)
```


## How are the different Disneyland branches performing? 


First, let's see what each branch's average rating is.

```{r, message=FALSE, cache=TRUE, echo=FALSE}
table <- disney_data %>%
  group_by(Branch) %>% 
  summarise(average_rating = mean(Rating))

knitr::kable(table)
```


Next, let's check the distrubution of ratings. 

```{r, message=FALSE, cache=TRUE, echo=FALSE}
ggplot(data = disney_data, aes(as.numeric(Rating)))+
  geom_histogram(fill="#add8e6", bins = 5, color="black") + xlab("\nRating") + 
  ggtitle("Distribution of Disneyland Review Ratings")+ theme_minimal()
```

Overall, the reviews are fairly high and the average rating is ~4. Finally, let's see how the parks have performed for the past years and see if there's any seasonal fluctuation in ratings. 


```{r, message=FALSE, cache=TRUE, echo=FALSE, fig.width=11,fig.height=6}
disney_data %>% 
  filter(Year_Month != "missing") %>% 
  mutate(year= substr(Year_Month, 1, 4)) %>%
  group_by(year, Branch) %>% 
  summarise(avg_score=mean(Rating)) %>% 
  ggplot(aes(x=year, y=avg_score))+geom_col(aes(fill=Branch)) +
  facet_wrap(~Branch, scales = "free") + theme_minimal()+ 
  theme(legend.position = "null", plot.title = element_text(hjust=.5), 
        text = element_text(size=20), 
        axis.text.x  = element_text(size=14, angle=90)) + 
  xlab("\nYear") + ylab("Averge Rating\n") + 
  ggtitle("Average Yearly Rating By Park\n") + 
  facet_wrap(~Branch, scales = "free") 
 
```


```{r, message=FALSE, cache=TRUE, echo=FALSE, fig.width=11,fig.height=6}
disney_data %>% 
  filter(Year_Month != "missing") %>% 
  mutate(month= substr(Year_Month, 6, 7)) %>%
  group_by(month, Branch) %>% 
  summarise(avg_score=mean(Rating)) %>% 
  ggplot(aes(x=as.numeric(month), y=avg_score))+geom_col(aes(fill=Branch)) +
  scale_x_continuous(breaks=seq(1,12,1)) + 
  theme_minimal()+ theme(legend.position = "null", 
                         plot.title = element_text(hjust=.5), 
                         text = element_text(size=20),
                         axis.text.x  = element_text(size=12)) + 
  xlab("\nMonth") + ylab("Averge Rating\n") + 
  ggtitle("Average Monthly Rating By Park\n") + 
  facet_wrap(~Branch, scales = "free")
```


## What rides are reviewers talking the most about? 

For this question, we need to use fuzzy matching against a list of all the rides in the parks.

To do that, we'll just need to use a while loop to count how many approximate matches each ride has. We'll repeat this process for every park.  


```{r, message=FALSE, cache=TRUE, echo=T}
ride_data <- read.xlsx("Rides_Data.xlsx")

#Filter for Cali
cali_ride_data <- filter(ride_data, Park=="Disneyland California")
cali_data <- filter(disney_data, Branch=="Disneyland_California")
dataset <- cali_data$Review_Text

#Count cali ride popularity
rides <- cali_ride_data$Attraction
i=1
result <- vector("list", length(rides))
while (i <= length(rides)) { 
  ride_to_search <- rides[i]
  result[[i]] <- length(test <- agrep(ride_to_search,dataset,value=T))
  i = i+1
}
#Collect results
df <- data.frame(matrix(unlist(result), nrow=length(result), byrow=TRUE))
cali_ride_data$occurence_count <- df$matrix.unlist.result...nrow...length.result...byrow...TRUE.
```

```{r, message=FALSE, cache=TRUE, echo=FALSE}
#Filter for Paris
paris_ride_data <- filter(ride_data, Park=="Disneyland Paris")
paris_data <- filter(disney_data, Branch=="Disneyland_Paris")
dataset <- paris_data$Review_Text

#Count Paris ride popularity
rides <- paris_ride_data$Attraction
i=1
result <- vector("list", length(rides))
while (i <= length(rides)) { 
  ride_to_search <- rides[i]
  result[[i]] <- length(test <- agrep(ride_to_search,dataset,value=T))
  i = i+1
}
#Collect Results
df <- data.frame(matrix(unlist(result), nrow=length(result), byrow=TRUE))
paris_ride_data$occurence_count <- df$matrix.unlist.result...nrow...length.result...byrow...TRUE.


#Filter for Hong Kong
hong_kong_ride_data <- filter(ride_data, Park=="Hong Kong Disneyland")
hk_data <- filter(disney_data, Branch=="Disneyland_HongKong")
dataset <- hk_data$Review_Text

#Count paris ride popularity
rides <- hong_kong_ride_data$Attraction
i=1
result <- vector("list", length(rides))
while (i <= length(rides)) { 
  ride_to_search <- rides[i]
  result[[i]] <- length(test <- agrep(ride_to_search,dataset,value=T))
  i = i+1
}
#Collect Results
df <- data.frame(matrix(unlist(result), nrow=length(result), byrow=TRUE))
hong_kong_ride_data$occurence_count <- df$matrix.unlist.result...nrow...length.result...byrow...TRUE.

```


After we repeat this process for all the parks, we can combine our results into one dataframe and start making visualizations.

```{r, message=FALSE, cache=TRUE, echo=TRUE}
all_ride_data <- rbind(hong_kong_ride_data, paris_ride_data, cali_ride_data)
all_ride_data <- 
  all_ride_data[order(all_ride_data$occurence_count, decreasing = TRUE),]
```

Now let's see what each park's most popular rides are. 

```{r, message=FALSE, cache=TRUE, echo=FALSE, fig.width=11,fig.height=6}
all_ride_data %>% 
  group_by(Park) %>% 
  top_n(n=12)%>%
  ggplot(mapping=aes(reorder(Attraction, occurence_count), y=occurence_count)) + 
  geom_col(aes(fill=Park))+ coord_flip() + xlab("Ride") + ylab("\nCount") + 
  ggtitle("Most Talked About Rides") + theme_fivethirtyeight()+ 
  theme(plot.title = element_text(hjust = .5), legend.position = "null")+ facet_wrap(~Park, scales="free")
```

This is interesting because it gives us another metric for customer engagement in the parks. Whereas Disney has easy access to ridership numbers in their parks, by using fuzzy matching and NLP we can see what rides customers talk about the most. Further, if we wanted to we could easily filter the most talked about rides for each rating. 

Interestingly, Disneyland California has more instances of users discussing thrilling rides (such as space mountain), as compared to Paris and Hong Kong which have their most talked about rides being rides which are slower experiential rides (such as pirates). 

## What are reviewers saying about Disneyland? 

For this next section, let's see what people are generally saying about the Disneyland parks. To do this, we're going to find the most commmon 2 word combinations people are saying in these 42,000 reviews. 

```{r, message=FALSE, cache=TRUE, echo=TRUE}
ngram_data <- disney_data
ngram_data$Rating <- as.factor(ngram_data$Rating)

#Clean our text field 
ngram_data$clean_text <- ngram_data$Review_Text %>% 
  removeNumbers() %>% 
  tolower() %>% 
  removePunctuation() %>% 
  removeWords(stop_words$word)

#Make bigrams by branch and rating
bigram_by_branch_rating <- ngram_data %>%
  group_by(Branch, Rating) %>%
  unnest_tokens(word, clean_text,token = "ngrams", n = 2) %>% 
  dplyr::count(word, sort = TRUE)%>%
  filter(row_number() <= 10)
```

After running this code, we'll have a dataframe with the most common words said about each branch and for each rating. Let's see what people are most commonly saying at Disneyland California per rating. 

```{r, message=FALSE, cache=TRUE, echo=FALSE, fig.width=11,fig.height=8}
bigram_by_branch_rating %>% 
  filter(Branch=="Disneyland_California")%>% 
  group_by(Rating) %>% 
  ggplot(mapping = aes(reorder_within(word, n, Rating), y=n))+ 
  geom_col(aes(fill=Rating)) + 
  coord_flip()+ scale_x_reordered()+
  facet_wrap(~Rating, scales = "free")+ theme_minimal()+ xlab("Bigrams\n")+
  ylab("\nCount") + 
  ggtitle("Most Common 2 Words Used in Disneyland California Reviews by Rating")+
  theme(legend.position = "null", plot.title = element_text(hjust = .5)) 
```

As we can see from this graph, low rated reviews tend to mention things such as "wait times" more often than higher rated reviews. 


## What are some positive things guests say about the parks? 

For this section, we just want to see the most common positive words said in all reviews. For this, we can use sentiment analysis and then view the positive words said about each Disneyland park. 

```{r, message=FALSE, cache=TRUE, echo=FALSE, fig.width=11,fig.height=6}
nrc_sent <- tibble(get_sentiments("nrc"))
text <- ngram_data$clean_text
text_df <- tibble(text)
text_df$row_num <- seq(1:length(text))
text_df <- text_df %>%
  group_by(row_num) %>%
  unnest_tokens(word, text)

cali_index <- ngram_data %>% 
  mutate(ID= seq(1:nrow(ngram_data))) %>% 
  filter(Branch=="Disneyland_California")
cali_index <- cali_index$ID

#Find which rows are for Paris
paris_index <- ngram_data %>% 
  mutate(ID= seq(1:nrow(ngram_data))) %>% 
  filter(Branch=="Disneyland_Paris")
paris_index <- paris_index$ID

#Filter only for positive words
positive_words <- text_df %>%
  left_join(nrc_sent)%>% 
  filter(sentiment=="positive"|sentiment=="joy")

#Create a new park column
positive_words$park <- ifelse(positive_words$row_num %in% cali_index, "Disneyland California", 0)
positive_words$park <- ifelse(positive_words$row_num %in% paris_index, "Disneyland Paris", positive_words$park)
positive_words$park <- ifelse(positive_words$park == "Disneyland Paris"| positive_words$park== "Disneyland California", 
                              positive_words$park, "Hong Kong Disneyland")

#Count positive words by park and word
positive_words <- positive_words %>% 
  group_by(park, word) %>% 
  count(word, sort = T)

#Plot the 20 most common positive words per park
positive_words %>% 
  group_by(park) %>% 
  top_n(12)%>% 
  ggplot(mapping = aes(reorder_within(word, n, park), y=n)) + geom_col(aes(fill=park))+ coord_flip()+ 
  scale_x_reordered()+ facet_wrap(~park, scales="free") +
  xlab("Positive Word\n")+ylab("\nCount") + ggtitle("Most Common Positive Words Per Park\n")+
  theme(legend.position = "null", plot.title = element_text(hjust = .5))

```



## What are some negative things guests say about the parks?

Similar to before, we want to see all the negative words used in reviews by park. 


```{r, message=FALSE, cache=TRUE, echo=FALSE, fig.width=11,fig.height=6}
negative_words <- text_df %>%
  left_join(nrc_sent)%>% 
  filter(sentiment=="anger"|sentiment=="negative") %>% 
  filter(word !="parade"& word !="haunted" & word !="buffet"&
           word !="treat" & word!="blast")
#Create a park column again
negative_words$park <- ifelse(negative_words$row_num %in% cali_index, "Disneyland California", 0)
negative_words$park <- ifelse(negative_words$row_num %in% paris_index, "Disneyland Paris", negative_words$park)
negative_words$park <- ifelse(negative_words$park == "Disneyland Paris"| negative_words$park== "Disneyland California", 
                              negative_words$park, "Hong Kong Disneyland")

#Count negative words by park and word
negative_words <- negative_words %>% 
  group_by(park, word) %>% 
  count(word, sort = T)

#Plot the 20 most common negative words per park
negative_words %>%
  group_by(park) %>% 
  top_n(12)%>% 
  ggplot(mapping = aes(reorder_within(word, n, park), y=n)) + geom_col(aes(fill=park))+ coord_flip()+ 
  scale_x_reordered()+ facet_wrap(~park, scales="free") +
  xlab("Positive Word\n")+ylab("\nCount") + ggtitle("Most Common Negative Words Per Park\n")+
  theme(legend.position = "null", plot.title = element_text(hjust = .5))
```



